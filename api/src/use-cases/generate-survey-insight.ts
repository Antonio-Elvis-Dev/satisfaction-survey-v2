import { SurveysRepository } from "@/repositories/surveys-repository";
import { ResourceNotFoundError } from "./erros/resource-not-found-error";

import { groq } from '@ai-sdk/groq';
import { generateText } from 'ai';

import { env } from "@/env";
import { prisma } from "@/lib/prisma";

interface GenerateAiInsightRequest {
    surveyId: string;
}

export class GenerateAiInsightUseCase {
    constructor(private surveysRepository: SurveysRepository) { }

    async execute({ surveyId }: GenerateAiInsightRequest) {
        // 1. Busca a pesquisa e TODAS as respostas
        const survey = await prisma.survey.findUnique({
            where: { id: surveyId },
            include: {
                question: {
                    include: {
                        responses: true
                    }
                }
            }
        });

        if (!survey) {
            throw new ResourceNotFoundError();
        }

        // 2. Filtra e Formata as Respostas
        const textInputs: string[] = [];

        survey.question.forEach(q => {
            q.responses.forEach(r => {
                if (r.text_response && r.text_response.trim().length > 3) {
                    textInputs.push(`Pergunta: "${q.question_text}" | Resposta do Usu√°rio: "${r.text_response}"`);
                }
            });
        });

        if (textInputs.length < 3) {
            return {
                analysis: "N√£o h√° respostas textuais suficientes nesta pesquisa para gerar uma an√°lise qualitativa com IA. Aguarde mais respostas."
            };
        }

        const dataForAi = textInputs.slice(0, 60).join("\n");

        // 3. Inicializa Gemini (Google Generative AI)
        // ‚ö†Ô∏è Certifique-se de que env.GEMINI_API_KEY est√° no seu .env e no env/index.ts
        // const genAI = new GoogleGenerativeAI(env.GEMINI_API_KEY);

        // Usamos o modelo 'gemini-1.5-flash' que √© r√°pido e barato (equivalente ao gpt-4o-mini)
        // const model = genAI.getGenerativeModel({ model: "gemini-pro" });

        // 4. O Prompt
        const prompt = `
            Voc√™ √© um Consultor S√™nior de Customer Experience (CX) e An√°lise de Dados.
            
            Analise os dados da seguinte pesquisa de satisfa√ß√£o:
            **T√≠tulo da Pesquisa:** ${survey.title}
            **Total de Respostas Coletadas:** ${survey.total_responses}

            Abaixo est√£o os coment√°rios reais dos usu√°rios:
            ---
            ${dataForAi}
            ---

            Com base APENAS nestes dados, gere um relat√≥rio em Markdown com a seguinte estrutura:
            
            ### üìä Resumo Executivo
            (Um par√°grafo resumindo o sentimento geral: Positivo, Neutro ou Negativo e porqu√™).

            ### üò° Principais Pontos de Dor (Reclama√ß√µes)
            (Liste em bullet points os problemas mais recorrentes).

            ### üíö Pontos Fortes (Elogios)
            (O que a empresa est√° fazendo certo).

            ### üöÄ Plano de A√ß√£o Sugerido
            (3 sugest√µes pr√°ticas e diretas para melhorar os resultados baseadas nas reclama√ß√µes).

            Use uma linguagem profissional, direta e emp√°tica.
        `;

        // 5. Chamada √† API e Tratamento da Resposta (AQUI ESTAVA O ERRO)
        try {
            // const result = await model.generateContent(prompt);
            // const response = await result.response;

            // üëá No Gemini, pegamos o texto assim, e n√£o via choices[0]
            const { text } = await generateText({
                model: groq('llama-3.3-70b-versatile'),
                prompt: prompt,
            });

            console.log(text)
            return { analysis: text };

        } catch (error) {
            console.error("Erro na gera√ß√£o do Gemini:", error);
            throw new Error("Falha ao gerar insights com Gemini");
        }
    }
}